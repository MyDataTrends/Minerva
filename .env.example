# ─────────────────────────────────────────────────────────────────────────────
# Assay — environment configuration template
# Copy this file to `.env` and fill in the values you need.
# All keys are optional unless marked REQUIRED.
# ─────────────────────────────────────────────────────────────────────────────

# ── Cloud LLM (required for AI features without a local model) ────────────────
ANTHROPIC_API_KEY=

# ── Public data APIs (all optional) ──────────────────────────────────────────
FRED_API_KEY=
ALPHA_VANTAGE_API_KEY=
CENSUS_API_KEY=

# ── Local LLM (optional — set ENABLE_LOCAL_LLM=1 to auto-download Mistral 7B)
# Warning: first-run download is ~4 GB; model stored in the models/ volume.
ENABLE_LOCAL_LLM=0
AUTO_DOWNLOAD_LLM=0
# Override the model path if you supply your own GGUF file via volume mount:
MISTRAL_MODEL_PATH=models/mistral-7b-instruct-v0.2.Q4_K_M.gguf

# ── Storage (local filesystem by default — no AWS needed) ────────────────────
USE_CLOUD=False
LOCAL_DATA_DIR=local_data

# ── AWS (only needed when USE_CLOUD=True) ────────────────────────────────────
AWS_REGION=us-east-1
BUCKET_NAME=
SEMANTIC_INDEX_KEY=semantic_index.db
TABLE_NAME=UserJobs
SNS_TOPIC_ARN=

# ── Logging ──────────────────────────────────────────────────────────────────
LOG_LEVEL=INFO
LOG_DIR=logs

# ── Agents (GitHub integration for Advocate / Conductor) ─────────────────────
GITHUB_TOKEN=

# ── Dev mode — disables LLM calls and Prometheus; faster startup ─────────────
DEV_MODE=false

# ── MCP server ───────────────────────────────────────────────────────────────
MCP_ENABLED=1
MCP_HOST=0.0.0.0
MCP_PORT=8766
