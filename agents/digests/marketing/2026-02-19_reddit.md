# Marketing Draft — Reddit (2026-02-19)

> Auto-generated by MarketingAgent. Review and edit before posting.

---

TITLE: Built Minerva – a local-first AI data analyst that does the full pipeline (cleaning → modeling → SHAP) without sending data to the cloud

BODY:

Hey r/MachineLearning! I've been working on **Minerva**, a tool that basically acts like an autonomous data analyst on your machine. You drop in a CSV and it handles cleaning, profiling, trains models (LightGBM/XGBoost/Ridge), generates SHAP explanations, and writes natural language insights – all locally.

**What's new in this release:**

- **Interactive dashboard** – conversational interface where you can ask questions about your data and it auto-generates insights
- **Smart task planning** – breaks down complex requests into steps and picks the right tools/visualizations 
- **More data connectors** – expanded beyond CSV to connect with other platforms
- **Security updates** – patched vulnerabilities to keep local analysis safe

The core idea was scratching my own itch: I got tired of the repetitive EDA → feature engineering → model comparison → interpretation loop, especially when working with sensitive data that can't touch cloud APIs. Wanted something that could run the full pipeline autonomously while keeping everything on my laptop.

Currently handles tabular data pretty well, but curious what the community thinks about the "autonomous analyst" approach vs. traditional notebooks. Does full automation help or does it black-box too much of the process?

Also interested in feedback on what data sources you'd want to see supported next – been prioritizing based on what gets used most in DS workflows.

GitHub/demo links in profile. Happy to answer questions about the architecture or design choices!
