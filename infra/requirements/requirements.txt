matplotlib~=3.10.0
tokenizers==0.22.1
torch>=2.6.0,<2.7.0
spacy>=3.8.0,<3.9.0
https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl
openpyxl==3.1.5
pytest>=6.2.5
numpy~=2.3.0
pandas~=2.3.0
scikit-learn~=1.7.0
transformers>=4.57.0,<4.58.0
rapidfuzz~=3.0.0
boto3~=1.40.0
# Local LLM runtime (llama.cpp) â€“ skip on Windows to avoid build issues
llama-cpp-python==0.3.16 ; sys_platform != 'win32'
# HF Hub client compatible with transformers 4.57.x and tokenizers 0.22.x
huggingface-hub>=0.34.0,<1.0
setuptools~=80.9.0
wheel~=0.45.0
python-dotenv~=1.2.0
# pycaret replaced with compatible modeling stack
xgboost>=2.0.0,<2.1.0
lightgbm>=4.0.0,<4.1.0
catboost>=1.2,<1.3
scipy~=1.16.0
jupyter~=1.1.0
ipywidgets~=8.1.0
notebook~=7.4.0
flask~=3.1.0
fastapi~=0.121.0
prometheus_client~=0.23.0
structlog~=25.5.0
httpx~=0.28.0
streamlit~=1.51.0
uvicorn~=0.38.0
pyyaml~=6.0.0
requests~=2.32.0
responses~=0.25.0
moto~=5.1.0
pillow~=12.0.0
selenium~=4.38.0